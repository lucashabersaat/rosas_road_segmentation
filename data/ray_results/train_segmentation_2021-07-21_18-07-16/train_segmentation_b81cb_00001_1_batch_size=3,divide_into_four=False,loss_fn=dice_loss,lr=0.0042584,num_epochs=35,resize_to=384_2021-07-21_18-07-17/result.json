{"loss": 0.7386404871940613, "time_this_iter_s": 4537.915077924728, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 1, "experiment_id": "e8155eb09c90464e9f6717cb425d8e73", "date": "2021-07-21_19-22-58", "timestamp": 1626888178, "time_total_s": 4537.915077924728, "pid": 70717, "hostname": "lo-a2-091", "node_ip": "10.204.4.71", "config": {"lr": 0.004258356611319623, "loss_fn": "noise_robust_dice", "batch_size": 4, "resize_to": 384, "divide_into_four": false, "num_epochs": 35, "transunet_config": "activation: softmax\nclassifier: seg\ndecoder_channels: !!python/tuple\n- 256\n- 128\n- 64\n- 16\nhidden_size: 768\nn_classes: 1\nn_skip: 3\npatch_size: 16\npatches:\n  grid: &id001 !!python/tuple\n  - 16\n  - 16\n  size: *id001\npretrained_path: ../model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\nrepresentation_size: null\nresnet:\n  num_layers: !!python/tuple\n  - 3\n  - 4\n  - 9\n  width_factor: 1\nresnet_pretrained_path: null\nskip_channels:\n- 512\n- 256\n- 64\n- 0\ntransformer:\n  attention_dropout_rate: 0.0\n  dropout_rate: 0.1\n  mlp_dim: 3072\n  num_heads: 12\n  num_layers: 12\n"}, "time_since_restore": 4537.915077924728, "timesteps_since_restore": 0, "iterations_since_restore": 1, "trial_id": "b81cb_00001"}
{"loss": 0.7259026765823364, "time_this_iter_s": 9590.15013051033, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 2, "experiment_id": "e8155eb09c90464e9f6717cb425d8e73", "date": "2021-07-21_22-02-48", "timestamp": 1626897768, "time_total_s": 14128.065208435059, "pid": 70717, "hostname": "lo-a2-091", "node_ip": "10.204.4.71", "config": {"lr": 0.004258356611319623, "loss_fn": "noise_robust_dice", "batch_size": 4, "resize_to": 384, "divide_into_four": false, "num_epochs": 35, "transunet_config": "activation: softmax\nclassifier: seg\ndecoder_channels: !!python/tuple\n- 256\n- 128\n- 64\n- 16\nhidden_size: 768\nn_classes: 1\nn_skip: 3\npatch_size: 16\npatches:\n  grid: &id001 !!python/tuple\n  - 16\n  - 16\n  size: *id001\npretrained_path: ../model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\nrepresentation_size: null\nresnet:\n  num_layers: !!python/tuple\n  - 3\n  - 4\n  - 9\n  width_factor: 1\nresnet_pretrained_path: null\nskip_channels:\n- 512\n- 256\n- 64\n- 0\ntransformer:\n  attention_dropout_rate: 0.0\n  dropout_rate: 0.1\n  mlp_dim: 3072\n  num_heads: 12\n  num_layers: 12\n"}, "time_since_restore": 14128.065208435059, "timesteps_since_restore": 0, "iterations_since_restore": 2, "trial_id": "b81cb_00001"}
