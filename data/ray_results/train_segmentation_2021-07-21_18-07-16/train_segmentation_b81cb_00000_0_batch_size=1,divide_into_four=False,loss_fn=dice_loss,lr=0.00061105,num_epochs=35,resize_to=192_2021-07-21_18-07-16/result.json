{"loss": 0.7062386274337769, "time_this_iter_s": 2454.7407863140106, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 1, "experiment_id": "abb07355c34649eca5aba1a96186ce98", "date": "2021-07-21_18-48-15", "timestamp": 1626886095, "time_total_s": 2454.7407863140106, "pid": 70679, "hostname": "lo-a2-091", "node_ip": "10.204.4.71", "config": {"lr": 0.0006110461682192326, "loss_fn": "noise_robust_dice", "batch_size": 4, "resize_to": 384, "divide_into_four": false, "num_epochs": 35, "transunet_config": "activation: softmax\nclassifier: seg\ndecoder_channels: !!python/tuple\n- 256\n- 128\n- 64\n- 16\nhidden_size: 768\nn_classes: 1\nn_skip: 3\npatch_size: 16\npatches:\n  grid: &id001 !!python/tuple\n  - 16\n  - 16\n  size: *id001\npretrained_path: ../model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\nrepresentation_size: null\nresnet:\n  num_layers: !!python/tuple\n  - 3\n  - 4\n  - 9\n  width_factor: 1\nresnet_pretrained_path: null\nskip_channels:\n- 512\n- 256\n- 64\n- 0\ntransformer:\n  attention_dropout_rate: 0.0\n  dropout_rate: 0.1\n  mlp_dim: 3072\n  num_heads: 12\n  num_layers: 12\n"}, "time_since_restore": 2454.7407863140106, "timesteps_since_restore": 0, "iterations_since_restore": 1, "trial_id": "b81cb_00000"}
{"loss": 0.6925321221351624, "time_this_iter_s": 2804.1386585235596, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 2, "experiment_id": "abb07355c34649eca5aba1a96186ce98", "date": "2021-07-21_19-34-59", "timestamp": 1626888899, "time_total_s": 5258.87944483757, "pid": 70679, "hostname": "lo-a2-091", "node_ip": "10.204.4.71", "config": {"lr": 0.0006110461682192326, "loss_fn": "noise_robust_dice", "batch_size": 4, "resize_to": 384, "divide_into_four": false, "num_epochs": 35, "transunet_config": "activation: softmax\nclassifier: seg\ndecoder_channels: !!python/tuple\n- 256\n- 128\n- 64\n- 16\nhidden_size: 768\nn_classes: 1\nn_skip: 3\npatch_size: 16\npatches:\n  grid: &id001 !!python/tuple\n  - 16\n  - 16\n  size: *id001\npretrained_path: ../model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\nrepresentation_size: null\nresnet:\n  num_layers: !!python/tuple\n  - 3\n  - 4\n  - 9\n  width_factor: 1\nresnet_pretrained_path: null\nskip_channels:\n- 512\n- 256\n- 64\n- 0\ntransformer:\n  attention_dropout_rate: 0.0\n  dropout_rate: 0.1\n  mlp_dim: 3072\n  num_heads: 12\n  num_layers: 12\n"}, "time_since_restore": 5258.87944483757, "timesteps_since_restore": 0, "iterations_since_restore": 2, "trial_id": "b81cb_00000"}
